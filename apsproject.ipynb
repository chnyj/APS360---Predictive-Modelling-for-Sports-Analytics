{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4i7PqXhkVRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "344f26f7-4f3c-4d33-8c2f-cbdb999e0c4b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nba_api'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-38375b361a56>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnba_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplayercareerstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnba_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nba_api'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from nba_api.stats.endpoints import playercareerstats\n",
        "from nba_api.stats.static import players\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from requests.exceptions import ReadTimeout\n",
        "\n",
        "\n",
        "#obtaining data from nba_api, standard json access and conversion code\n",
        "def fetch_player_career_stats(player_id, timeout=None):\n",
        "    max_retries = 3\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            player_career = playercareerstats.PlayerCareerStats(\n",
        "                player_id=player_id,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            return player_career.get_data_frames()[0]\n",
        "        except ReadTimeout as e:\n",
        "            retries += 1\n",
        "            print(f\"Read timeout. Retrying... (Attempt {retries}/{max_retries})\")\n",
        "    raise Exception(\"Failed to fetch data after multiple retries.\")\n",
        "\n",
        "# Timeout\n",
        "timeout = 100\n",
        "\n",
        "# Get all players\n",
        "all_players = players.get_players()\n",
        "\n",
        "# Initialize an empty list to store player dfs\n",
        "career_dfs = []\n",
        "\n",
        "# using tqdm to measure conversion process\n",
        "for player in tqdm(all_players, desc=\"Processing Players\"):\n",
        "    player_id = player['id']\n",
        "\n",
        "    # Get player career stats with custom settings\n",
        "    try:\n",
        "        career_df = fetch_player_career_stats(\n",
        "            player_id=player_id,\n",
        "            timeout=timeout\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for Player ID {player_id}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # make sure df is applicable for our criteria of 5 Y period\n",
        "    if any((career_df['SEASON_ID'] >= '2018') & (career_df['SEASON_ID'] <= '2023')):\n",
        "\n",
        "        # Filter df for 2018-2023\n",
        "        mask = (career_df['SEASON_ID'] >= '2018') & (career_df['SEASON_ID'] <= '2023')\n",
        "        career_df_filtered = career_df.loc[mask].copy()\n",
        "\n",
        "        # Add player to df\n",
        "        career_df_filtered['Player_ID'] = player_id\n",
        "        career_df_filtered['Player_Name'] = player['full_name']\n",
        "\n",
        "        # Append df to the list\n",
        "        career_dfs.append(career_df_filtered)\n",
        "\n",
        "#combining all dfs\n",
        "all_players_df = pd.concat(career_dfs, ignore_index=True)\n",
        "\n",
        "#saving to csv\n",
        "csv_filename = 'all_players_career_stats_2018_2023.csv'\n",
        "csv_filepath = \"/content/data\" + csv_filename\n",
        "all_players_df.to_csv(csv_filepath, index=False)\n",
        "\n",
        "print(f\"CSV file saved to: {csv_filepath}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### FEATURE SELECTION ######\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "def custom_feature_selection(data_path):\n",
        "    players_data = pd.read_csv(data_path)\n",
        "    players_data = players_data.iloc[:, 5:-2]\n",
        "\n",
        "    # Define target variable (to be predicted)\n",
        "    target_variable = 'FG3M'\n",
        "\n",
        "    # Calculate correlations\n",
        "    correlations = players_data.corr()[target_variable].abs().sort_values(ascending=False)\n",
        "\n",
        "    # Select top correlated features\n",
        "    selected_features = correlations.index[1:10]\n",
        "\n",
        "    # Extract features and target\n",
        "    X = players_data[selected_features]\n",
        "    y = players_data[target_variable].values\n",
        "\n",
        "    # Split data: train, val, test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Create model\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # RFE\n",
        "    feature_selector = RFE(model, n_features_to_select=9)\n",
        "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
        "    selected_features_rfe = X.columns[feature_selector.support_]\n",
        "\n",
        "    # Print selected features\n",
        "    print(\"Top 8 Correlated Features:\", selected_features_rfe[1:10])\n",
        "\n",
        "    return X_train_selected, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "Pd4F-rBXmGE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### BASELINE MODEL ######\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Random Forest Regressor model\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_regressor.fit(X_train_rfe, y_train)  # Use the filtered X_train_rfe data\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_val = rf_regressor.predict(X_val)  # Use the filtered X_val data\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "mse_val = mean_squared_error(y_val, y_pred_val)\n",
        "r2_val = r2_score(y_val, y_pred_val)\n",
        "\n",
        "print(\"Mean Squared Error (MSE) on Validation Set:\", mse_val)\n",
        "print(\"R-squared (R2) on Validation Set:\", r2_val)\n",
        "\n",
        "#plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_val, y_pred_val, color='blue', alpha=0.5, label='Predicted')\n",
        "plt.scatter(y_val, y_val, color='red', alpha=0.5, label='Actual')\n",
        "plt.title('Actual vs. Predicted Values (Validation Set)')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7x48FQdomAw9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ef9604cd-c284-4263-aac6-361e32d1fc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_rfe' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-602a25e69680>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrf_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_rfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the filtered X_train_rfe data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Predict on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_rfe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### RNN-LSTM MODEL ######\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# class LSTM_next(nn.Module):\n",
        "#   def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "#     super(LSTM, self).__init__()\n",
        "#     self.hidden_size = hidden_size\n",
        "#     self.input_size = input_size\n",
        "#     self.output_size = output_size\n",
        "#     self.num_layers = num_layers\n",
        "\n",
        "#     self.lstm = nn.LSTM(input_size, hidden_size, num_layers = 1, batch_first = True)\n",
        "#     self.fc1 =  nn.Linear(hidden_size, num_layers)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
        "#     c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
        "#     out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "#     hn = hn[-1, :, :]\n",
        "#     out = self.fc1(hn)\n",
        "#     return out\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, batch_first = True)\n",
        "    self.fc1 =  nn.Linear(hidden_size, num_layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "    out, __ = self.rnn(x, h0)\n",
        "    return self.fc(out[:, -1, :])\n",
        "\n",
        "# instatiation\n",
        "input_size = 9\n",
        "hidden_size = 1\n",
        "output_size = 1\n",
        "num_layers = 1\n",
        "\n",
        "model1 = LSTM(input_size, hidden_size, num_layers)\n",
        "\n",
        "# preparing data\n",
        "data_path = 'data_2018_2023.csv'\n",
        "players_data = pd.read_csv(data_path)\n",
        "players_data = players_data.iloc[:, 5:-2]\n",
        "\n",
        "# Define target variable (to be predicted)\n",
        "target_variable = 'FG3M'\n",
        "\n",
        "# Calculate correlations\n",
        "correlations = players_data.corr()[target_variable].abs().sort_values(ascending=False)\n",
        "\n",
        "# Select top correlated features\n",
        "selected_features = correlations.index[1:10]\n",
        "\n",
        "# Extract features and target\n",
        "X = players_data[selected_features]\n",
        "y = players_data[target_variable].values\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "# Split data: train, val, test\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "x_train_tensor = torch.Tensor(x_train.values)\n",
        "x_val_tensor = torch.Tensor(x_val.values)\n",
        "y_train_tensor = torch.Tensor(y_train)\n",
        "y_val_tensor = torch.Tensor(y_val)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 4\n",
        "\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# training\n",
        "\n",
        "\n",
        "def training(model, criterion, optimizer, train_loader, val_loader, epochs, lr):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x_train, y_train in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      pred = model1(x_train)\n",
        "      loss = criterion(pred, y_train)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    for x_val, y_val in val_loader:\n",
        "      pred = model(x_val)\n",
        "      val_loss += criterion(pred, y_val).item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "lr = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr = lr)\n",
        "\n",
        "training(model1, criterion, optimizer, train_loader, val_loader, epochs = 4, lr = 0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F11lZwTKl-uE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "cbb8b07f-ea97-4326-9c94-0252b7da4338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      FG3A  FGA  PTS     MIN  FGM  TOV  STL  GP  GS\n",
            "0      127  157  165   588.0   56   14   17  31   2\n",
            "1        1  228  304   737.0  124   43   20  61   4\n",
            "2      156  603  664  1725.0  265   84   37  73  28\n",
            "3      108  404  508  1141.0  196   59   31  55  12\n",
            "4       15   18   17   123.0    4    4    1  10   0\n",
            "...    ...  ...  ...     ...  ...  ...  ...  ..  ..\n",
            "3550     0  379  525  1039.0  212   70   14  59  37\n",
            "3551     2  385  596  1326.0  236   61   16  72  70\n",
            "3552     4  394  650  1609.0  257   81   24  72  33\n",
            "3553     0  495  785  1852.0  310  114   36  76  76\n",
            "3554     2  514  818  2169.0  326  117   29  76  76\n",
            "\n",
            "[3555 rows x 9 columns]\n",
            "[41  0 56 ...  1  0  0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f0f3e3bb25c1>\u001b[0m in \u001b[0;36m<cell line: 120>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-f0f3e3bb25c1>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-f0f3e3bb25c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                         raise RuntimeError(\n\u001b[0m\u001b[1;32m    531\u001b[0m                             f\"For unbatched 2-D input, hx should also be 2-D but got {hx.dim()}-D tensor\")\n\u001b[1;32m    532\u001b[0m                     \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
          ]
        }
      ]
    }
  ]
}